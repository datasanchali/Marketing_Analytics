# Ad Campaign Effectiveness Report

Welcome! This project analyzes how effective a recent digital ad campaign was â€” helping you understand whether your ads are really driving conversions and when your audience is most engaged.

## Goal

We wanted to answer:
- Does showing ads actually lead to more sign-ups or purchases?
- When are users most active and likely to convert?
- Is our ad spend paying off?

To find out, we ran an **A/B test**:
- **Group A (Control)** saw no ads.
- **Group B (Test)** saw digital ads.

We then compared how many users converted (e.g., signed up or bought something) in each group.

## Findings?

### âœ… Ads Had an Impact
- Users who saw ads **converted more often** than those who didnâ€™t.
- This suggests the campaign had a **positive effect** on user behavior.

### ğŸ•’ Timing Matters
- Most ad views happened on **Mondays and Tuesdays**.
- Peak engagement times were around **10 AM, 2 PM, 6 PM, 8 PM, and 10 PM**.
- This tells us **when to run ads** for the biggest impact.

### ğŸ’° Smarter Budgeting
- The results help identify the **best time slots** for ad placement.
- You can **optimize budget** by focusing on high-engagement periods.

## ğŸ“Š What's in the Report?

- Easy-to-read charts showing ad performance by time and day.
- Conversion comparisons between users who saw ads and those who didnâ€™t.
- Insights you can use in **media buying and campaign planning**.

## ğŸ¯ Key Takeaways

- The campaign **worked** â€” ads boosted user action.
- Focus on **early weekdays** and **evening hours** for future campaigns.
- This type of testing helps ensure **your budget is well spent**.

---

Want to dig deeper or see visual summaries? Just open the notebook file:  
ğŸ“ **`Campaign_Effectiveness.ipynb`**
